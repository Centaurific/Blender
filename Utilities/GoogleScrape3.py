## Scrapes the text from the first n pages on a Google search.
import os
UtilPath = os.getenv('HOME') + '/Documents/Blender/Utilities'
os.chdir(UtilPath)
import scraperfunctions
BlenderPath = os.getenv('HOME') + '/Documents/Blender'
os.chdir(BlenderPath)

import pickle
import time
from pyvirtualdisplay import Display

start_time = time.time() # For timing the whole operation

search_text = input("What do you seek? ") # Gives us our goal
pages = int(input("How many pages of results would you like? "))

with open("search_text.p", "wb") as f:
    pickle.dump(search_text, f)

scraperfunctions.google_scrape(search_text, pages, True)

### Open the virtual display
##display = Display()
##display.start()
##
### Gather a list of urls generated by Google according to the search term
##address_book = scraperfunctions.gather_urls(search_text, pages)
##
### Close the virtual display
##display.stop()
##
##print (address_book)
##
### Scrape the text from each page, clean it, and write it to a 
### pickled file ('output.p')
### Also get a list of difficult web pages
##trouble_child = scraperfunctions.retrieve_text(address_book) 
##
##print ('Text from %i web pages scanned.' % (len(address_book)-len(trouble_child)))
##t=time.time()-start_time
##ts = t % 60
##tm = t // 60
##print ('----- %i minutes, %i seconds -----' % (tm, ts))
##if len(trouble_child) == 0:
##    print ("All pages successfully scanned.")
##if len(trouble_child) == 1:
##    print ("1 problem child: ", trouble_child)
##if len(trouble_child) > 1:
##    print("%i problem children: " %len(trouble_child), 
##    	trouble_child)
