## Scrapes the text from the first n pages on a Google search.

import scraperfunctions
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions
import time
import random
import requests
import pickle

start_time=time.time() # For timing the whole operation

search_text=input("What do you seek? ") # Gives us our goal
pages=int(input("How many pages of results would you like? "))

# Gather a list of urls generated by Google according to the search term
address_book=scraperfunctions.gather_urls(search_text, pages)

print (address_book)

# Scrape the text from each page, clean it, and write it to a pickled file ('output.p')
scraperfunctions.retrieve_text(address_book)

print ('Text from %s web pages scanned.' % len(address_book))
t=time.time()-start_time
ts = t % 60
tm = t // 60
print ('----- %s minutes, %s seconds -----' % (tm, ts))
