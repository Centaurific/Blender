## Scrapes the text from the first n pages on a Google search.
import os
BlenderPath = os.getenv('HOME') + '/Documents/Blender'
AuxPath = os.getenv('HOME') + '/Documents/Blender/Aux'
os.chdir(BlenderPath)

import scraperfunctions
import pickle
import time
from pyvirtualdisplay import Display

start_time = time.time() # For timing the whole operation

search_text = input("What do you seek? ") # Gives us our goal
pages = int(input("How many pages of results would you like? "))

with open("output2.p", "wb") as f:
    pickle.dump(search_text, f)

# Open the virtual display
display = Display()
display.start()

# Gather a list of urls generated by Google according to the search term
address_book = scraperfunctions.gather_urls(search_text, pages)

# Close the virtual display
display.stop()

print (address_book)

# Scrape the text from each page, clean it, and write it to a 
# pickled file ('output.p')
# Also get a list of difficult web pages
trouble_child = scraperfunctions.retrieve_text(address_book) 

print ('Text from %i web pages scanned.' % (len(address_book)-len(trouble_child)))
t=time.time()-start_time
ts = t % 60
tm = t // 60
print ('----- %i minutes, %i seconds -----' % (tm, ts))
if len(trouble_child) == 0:
    print ("All pages successfully scanned.")
if len(trouble_child) == 1:
    print ("1 problem child: ", trouble_child)
if len(trouble_child) > 1:
    print("%i problem children: " %len(trouble_child), 
    	trouble_child)
